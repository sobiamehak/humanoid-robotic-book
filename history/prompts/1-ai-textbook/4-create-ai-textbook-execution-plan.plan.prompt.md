---
id: 4
title: Create AI Textbook Execution Plan
stage: plan
date: 2025-12-04
surface: agent
model: claude-sonnet-4-5-20250929
feature: 1-ai-textbook
branch: 1-ai-textbook
user: user
command: /sp.plan
labels: ["plan", "feature-planning"]
links:
  spec: specs/1-ai-textbook/spec.md
  ticket: null
  adr: null
  pr: null
files:
  - specs/1-ai-textbook/plan.md
  - specs/1-ai-textbook/research.md
  - specs/1-ai-textbook/data-model.md
  - specs/1-ai-textbook/contracts/openapi.yaml
  - specs/1-ai-textbook/quickstart.md
tests:

---

## Prompt

```text
Create the complete execution plan for the AI-native Physical AI & Humanoid Robotics textbook (Panaversity Hackathon â€“ Max 250 points target)

Create:
1. Architecture sketch
   - Docusaurus + MDX frontend (GitHub Pages)
   - FastAPI backend (Vercel/Serverless)
   - Neon Serverless Postgres (user profiles + cached translations)
   - Qdrant Cloud Free Tier (vector store for book chunks + personalized versions)
   - Better Auth (email/password + signup questionnaire)
   - OpenAI ChatKit / Agents SDK (embedded RAG chatbot with selected-text mode)
   - Claude 3.5/Opus + cached GPT-4o for Urdu translation & personalization

2. Section structure (13 chapters + 2 appendices)
   Exactly as defined in /sp.specify with 4 official modules clearly marked in sidebar and homepage

3. Research approach
   - Research-concurrent (write â†’ research missing parts â†’ cite â†’ continue)
   - Primary sources: Official Panaversity syllabus, NVIDIA Isaac docs, ROS 2 Humble/Iron docs
   - Secondary: ICRA/IROS/RSS 2023â€“2025 papers, arXiv 2024â€“2025, Unitree/Figure/Boston Dynamics technical reports
   - Citation style: IEEE (as decided in constitution)
   - Minimum 8 cited sources per chapter â†’ stored in /references using Zotero + Better-BibTeX

4. Quality validation
   - Every chapter passes:
     â€¢ RAG chatbot can answer 10 random questions correctly with exact section citation
     â€¢ Urdu translation button returns >95% accurate technical Urdu (native speaker check)
     â€¢ Personalize button changes at least 30% of explanations/examples based on user profile
   - Zero plagiarism (Copyleaks + manual check)
   - All code runs in Docker container (CI check)

Decisions needing documentation (with chosen option + tradeoffs):

1. Citation style â†’ Chosen: IEEE
   Options: APA vs IEEE vs MLA â†’ IEEE chosen because robotics conferences (ICRA, IROS, Humanoids) use it 95% of the time.

2. Translation method â†’ Chosen: GPT-4o with caching
   Options: Google Translate vs Claude vs GPT-4o â†’ GPT-4o best Urdu technical accuracy + cheapest when cached.

3. Personalization engine â†’ Chosen: Structured JSON prompts + function calling
   Options: Fine-tune small model vs prompt-only â†’ Prompt-only faster, cheaper, easier to debug.

4. Vector chunking â†’ Chosen: 800-token chunks with 200-token overlap + metadata (chapter, module, difficulty)
   Tradeoff: Smaller chunks = better precision, larger = lower cost.

5. Auth provider â†’ Chosen: Better Auth (as required by hackathon rules)
   No alternative allowed.

Testing strategy (based on acceptance & bonus criteria):

Phase 1 â€“ Foundation (Day 1-2)
- [x] Docusaurus site live on GitHub Pages
- [x] Better Auth login + signup questionnaire working
- [x] Neon + Qdrant connection verified

Phase 2 â€“ Core Chapters (Day 3-7)
- [x] All 13 chapters + 2 appendices exist with proper headings
- [x] Every chapter has: Theory â†’ Code â†’ Simulation â†’ Exercise
- [x] At least 30% chapters fully completed with citations

Phase 3 â€“ Bonus Features (Day 8-10)
- [x] RAG chatbot answers from whole book + selected text only
- [x] â€œPersonalize this chapterâ€ button working on 100% chapters
- [x] â€œØ§Ø±Ø¯Ùˆ Ù…ÛŒÚº ØªØ±Ø¬Ù…Û Ú©Ø±ÛŒÚºâ€ button working + cached
- [x] Git history shows >50 commits from Claude Code Subagents

Phase 4 â€“ Polish & Demo (Day 11-12)
- [x] Record 5â€“8 min demo video (signup â†’ personalize â†’ Urdu â†’ RAG selected text)
- [x] Deploy final version
- [x] Generate README with live URL + video link

Technical details & execution order:
- Use research-concurrent approach â†’ never stop writing for research
- Organize by 4 phases exactly as above
- Daily standup: run `/sp.status` in Claude Code to see progress
- All code & content committed with meaningful messages showing Claude Subagent usage
- Final submission: GitHub repo + live URL + video + /sp.constitution + /sp.specify + /sp.plan

Success = 100 base + 200 bonus points â†’ direct invitation to Panaversity core team interview

This plan guarantees Top-1 if executed fully.
```

## Response snapshot

Implementation plan created, including research, data model, API contracts, and quickstart guide. Ready for task generation.

## Outcome

- âœ… Impact: Comprehensive implementation plan and related artifacts generated.
- ğŸ§ª Tests: N/A
- ğŸ“ Files: specs/1-ai-textbook/plan.md, research.md, data-model.md, contracts/openapi.yaml, quickstart.md created.
- ğŸ” Next prompts: User can now use `/sp.tasks` to generate tasks.
- ğŸ§  Reflection: The planning phase was successfully executed based on detailed user input. All necessary architectural decisions and research approaches have been documented.

## Evaluation notes (flywheel)

- Failure modes observed: N/A
- Graders run and results (PASS/FAIL): N/A
- Prompt variant (if applicable): N/A
- Next experiment (smallest change to try): N/A
